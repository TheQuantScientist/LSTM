{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing, Holt, SimpleExpSmoothing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, GRU, LSTM, Bidirectional\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('CSCO.csv')\n",
    "\n",
    "# Preprocess the data (Assuming 'Date' and 'Target' columns are present)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.set_index('Date')\n",
    "# If your data is not already sorted by date, you should sort it here\n",
    "data = data.sort_index()\n",
    "\n",
    "# Feature and target separation\n",
    "# Assuming the target variable is the last column\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features (needed for certain ML models like KNN, SVM, MLP)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Dictionary to hold models and their names\n",
    "models = {\n",
    "    'AdaBoost': AdaBoostRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Extra Trees': ExtraTreesRegressor(),\n",
    "    'Bagging': BaggingRegressor(),\n",
    "    'KNN (k=10)': KNeighborsRegressor(n_neighbors=10),\n",
    "    'MLP': MLPRegressor(max_iter=1000),\n",
    "    'KNN (k=5)': KNeighborsRegressor(n_neighbors=5),\n",
    "    'KNN (k=3)': KNeighborsRegressor(n_neighbors=3),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'SVR (RBF)': SVR(kernel='rbf'),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Elastic Net': ElasticNet(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'SVR (Poly)': SVR(kernel='poly'),\n",
    "    'SVR (Linear)': SVR(kernel='linear')\n",
    "}\n",
    "\n",
    "# Time series models like ETS require univariate data\n",
    "# For simplicity, let's assume we're dealing with univariate time series forecasting\n",
    "# This assumes that 'y' is a univariate time series\n",
    "\n",
    "# Fit and predict with each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    if 'KNN' in name or 'SVR' in name or 'MLP' in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    results[name] = mse\n",
    "    print(f'{name} MSE: {mse}')\n",
    "\n",
    "# ETS models\n",
    "ets_models = {\n",
    "    'Simple ETS': SimpleExpSmoothing,\n",
    "    'Double ETS (Holt)': Holt,\n",
    "    'Triple ETS (Holt-Winters)': ExponentialSmoothing\n",
    "}\n",
    "\n",
    "# Fit and predict with ETS models\n",
    "for name, ets_model in ets_models.items():\n",
    "    if name == 'Triple ETS (Holt-Winters)':\n",
    "        model = ets_model(y_train, seasonal='add', seasonal_periods=12).fit()\n",
    "    else:\n",
    "        model = ets_model(y_train).fit()\n",
    "    predictions = model.forecast(len(y_test))\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    results[name] = mse\n",
    "    print(f'{name} MSE: {mse}')\n",
    "\n",
    "# Deep Learning models require reshaping the data for time series forecasting\n",
    "# This is a complex process and would require further details about the dataset\n",
    "# Here is an example of how to define and train a simple LSTM model\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        LSTM(50),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Reshaping the data for LSTM (this is a simplified example and may not work directly with your dataset)\n",
    "# Assuming 'X_train_scaled' and 'X_test_scaled' are already scaled and are in 2D shape\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# Build and train the LSTM model\n",
    "lstm_model = build_lstm_model((X_train_reshaped.shape[1], 1))\n",
    "lstm_model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Predict and evaluate LSTM model\n",
    "lstm_predictions = lstm_model.predict(X_test_reshaped)\n",
    "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "results['LSTM'] = lstm_mse\n",
    "print(f'LSTM MSE: {lstm_mse}')\n",
    "\n",
    "# You would need to follow a similar process to create and train CNN, GRU, and Bidirectional LSTM models\n",
    "\n",
    "# Print all results\n",
    "for model_name, mse in results.items():\n",
    "    print(f'{model_name} - MSE: {mse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
